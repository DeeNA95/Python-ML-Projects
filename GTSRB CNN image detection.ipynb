{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7366466",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-09-13T09:17:45.334516Z",
     "iopub.status.busy": "2024-09-13T09:17:45.334085Z",
     "iopub.status.idle": "2024-09-13T09:17:47.368719Z",
     "shell.execute_reply": "2024-09-13T09:17:47.367034Z"
    },
    "papermill": {
     "duration": 2.04366,
     "end_time": "2024-09-13T09:17:47.371521",
     "exception": false,
     "start_time": "2024-09-13T09:17:45.327861",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34mMeta\u001b[0m/  Meta.csv  \u001b[01;34mTest\u001b[0m/  Test.csv  \u001b[01;34mTrain\u001b[0m/  Train.csv  \u001b[01;34mmeta\u001b[0m/  \u001b[01;34mtest\u001b[0m/  \u001b[01;34mtrain\u001b[0m/\r\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n",
    "%ls '/kaggle/input/gtsrb-german-traffic-sign/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8732f969",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-13T09:17:47.383679Z",
     "iopub.status.busy": "2024-09-13T09:17:47.382299Z",
     "iopub.status.idle": "2024-09-13T09:17:47.491784Z",
     "shell.execute_reply": "2024-09-13T09:17:47.490693Z"
    },
    "papermill": {
     "duration": 0.118,
     "end_time": "2024-09-13T09:17:47.494291",
     "exception": false,
     "start_time": "2024-09-13T09:17:47.376291",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Width  Height  Roi.X1  Roi.Y1  Roi.X2  Roi.Y2  ClassId  \\\n",
      "0     27      26       5       5      22      20       20   \n",
      "1     28      27       5       6      23      22       20   \n",
      "2     29      26       6       5      24      21       20   \n",
      "3     28      27       5       6      23      22       20   \n",
      "4     28      26       5       5      23      21       20   \n",
      "\n",
      "                             Path  \n",
      "0  Train/20/00020_00000_00000.png  \n",
      "1  Train/20/00020_00000_00001.png  \n",
      "2  Train/20/00020_00000_00002.png  \n",
      "3  Train/20/00020_00000_00003.png  \n",
      "4  Train/20/00020_00000_00004.png  \n"
     ]
    }
   ],
   "source": [
    "print(pd.read_csv('/kaggle/input/gtsrb-german-traffic-sign/Train.csv').head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27dabb0b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-13T09:17:47.505184Z",
     "iopub.status.busy": "2024-09-13T09:17:47.504455Z",
     "iopub.status.idle": "2024-09-13T09:18:31.660679Z",
     "shell.execute_reply": "2024-09-13T09:18:31.659615Z"
    },
    "papermill": {
     "duration": 44.164654,
     "end_time": "2024-09-13T09:18:31.663518",
     "exception": false,
     "start_time": "2024-09-13T09:17:47.498864",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "\n",
    "print(torch.cuda.is_available()) \n",
    "\n",
    "train_trans = transforms.Compose([\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.RandomResizedCrop(128, scale=(0.8, 1.0)),\n",
    "    transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((128,128))\n",
    "])\n",
    "\n",
    "data_train = ImageFolder(\n",
    "    '/kaggle/input/gtsrb-german-traffic-sign/Train',\n",
    "    transform= train_trans\n",
    ")\n",
    "\n",
    "dataloader_train = DataLoader(\n",
    "    data_train,\n",
    "    shuffle = True,\n",
    "    batch_size = 1000\n",
    ")\n",
    "\n",
    "#change dataloader batch size to 1 before running \n",
    "# image, label = next(iter(dataloader_train))\n",
    "# print(image.shape)\n",
    "# image = image.squeeze().permute(1,2,0)\n",
    "# print(image.shape)\n",
    "# plt.imshow(image)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49e5892a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-13T09:18:31.675155Z",
     "iopub.status.busy": "2024-09-13T09:18:31.674570Z",
     "iopub.status.idle": "2024-09-13T09:18:31.685524Z",
     "shell.execute_reply": "2024-09-13T09:18:31.684585Z"
    },
    "papermill": {
     "duration": 0.019566,
     "end_time": "2024-09-13T09:18:31.687936",
     "exception": false,
     "start_time": "2024-09-13T09:18:31.668370",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class TrafficSign(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.feature_extractor = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "            nn.ELU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding =1),\n",
    "            nn.ELU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Dropout(p=0.25),\n",
    "            nn.Flatten()\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(64*32*32, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.feature_extractor(x)\n",
    "        x= self.classifier(x)\n",
    "        return x \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a524454f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-13T09:18:31.699376Z",
     "iopub.status.busy": "2024-09-13T09:18:31.698316Z",
     "iopub.status.idle": "2024-09-13T15:02:01.695511Z",
     "shell.execute_reply": "2024-09-13T15:02:01.694336Z"
    },
    "papermill": {
     "duration": 20610.020784,
     "end_time": "2024-09-13T15:02:01.713406",
     "exception": false,
     "start_time": "2024-09-13T09:18:31.692622",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 loss is 3.3091\n",
      "Epoch 2 loss is 2.3014\n",
      "Epoch 3 loss is 1.7238\n",
      "Epoch 4 loss is 1.4345\n",
      "Epoch 5 loss is 1.2713\n",
      "Epoch 6 loss is 1.1471\n",
      "Epoch 7 loss is 1.0538\n",
      "Epoch 8 loss is 0.9752\n",
      "Epoch 9 loss is 0.9229\n",
      "Epoch 10 loss is 0.8717\n",
      "Epoch 11 loss is 0.8441\n",
      "Epoch 12 loss is 0.7929\n",
      "Epoch 13 loss is 0.7513\n",
      "Epoch 14 loss is 0.7148\n",
      "Epoch 15 loss is 0.6999\n",
      "Epoch 16 loss is 0.6868\n",
      "Epoch 17 loss is 0.6659\n",
      "Epoch 18 loss is 0.6396\n",
      "Epoch 19 loss is 0.6230\n",
      "Epoch 20 loss is 0.6129\n",
      "Epoch 21 loss is 0.5922\n",
      "Epoch 22 loss is 0.5851\n",
      "Epoch 23 loss is 0.5682\n",
      "Epoch 24 loss is 0.5595\n",
      "Epoch 25 loss is 0.5441\n",
      "Epoch 26 loss is 0.5392\n",
      "Epoch 27 loss is 0.5211\n",
      "Epoch 28 loss is 0.5229\n",
      "Epoch 29 loss is 0.5280\n",
      "Epoch 30 loss is 0.5051\n",
      "Epoch 31 loss is 0.4845\n",
      "Epoch 32 loss is 0.4870\n",
      "Epoch 33 loss is 0.4761\n",
      "Epoch 34 loss is 0.4787\n",
      "Epoch 35 loss is 0.4701\n",
      "Epoch 36 loss is 0.4691\n",
      "Epoch 37 loss is 0.4586\n",
      "Epoch 38 loss is 0.4602\n",
      "Epoch 39 loss is 0.4597\n",
      "Epoch 40 loss is 0.4448\n",
      "Epoch 41 loss is 0.4354\n",
      "Epoch 42 loss is 0.4309\n",
      "Epoch 43 loss is 0.4341\n",
      "Epoch 44 loss is 0.4141\n",
      "Epoch 45 loss is 0.4301\n",
      "Epoch 46 loss is 0.4275\n",
      "Epoch 47 loss is 0.4168\n",
      "Epoch 48 loss is 0.4146\n",
      "Epoch 49 loss is 0.4084\n",
      "Epoch 50 loss is 0.4062\n",
      "Epoch 51 loss is 0.4163\n",
      "Epoch 52 loss is 0.3856\n",
      "Epoch 53 loss is 0.3971\n",
      "Epoch 54 loss is 0.3866\n",
      "Epoch 55 loss is 0.3806\n",
      "Epoch 56 loss is 0.3697\n",
      "Epoch 57 loss is 0.3987\n",
      "Epoch 58 loss is 0.3777\n",
      "Epoch 59 loss is 0.3829\n",
      "Epoch 60 loss is 0.3741\n",
      "Epoch 61 loss is 0.3717\n",
      "Epoch 62 loss is 0.3645\n",
      "Epoch 63 loss is 0.3665\n",
      "Epoch 64 loss is 0.3569\n",
      "Epoch 65 loss is 0.3614\n",
      "Epoch 66 loss is 0.3543\n",
      "Epoch 67 loss is 0.3502\n",
      "Epoch 68 loss is 0.3487\n",
      "Epoch 69 loss is 0.3499\n",
      "Epoch 70 loss is 0.3593\n",
      "Epoch 71 loss is 0.3545\n",
      "Epoch 72 loss is 0.3416\n",
      "Epoch 73 loss is 0.3433\n",
      "Epoch 74 loss is 0.3474\n",
      "Epoch 75 loss is 0.3378\n",
      "Epoch 76 loss is 0.3501\n",
      "Epoch 77 loss is 0.3396\n",
      "Epoch 78 loss is 0.3402\n",
      "Epoch 79 loss is 0.3415\n",
      "Epoch 80 loss is 0.3413\n",
      "Epoch 81 loss is 0.3319\n",
      "Epoch 82 loss is 0.3259\n",
      "Epoch 83 loss is 0.3298\n",
      "Epoch 84 loss is 0.3279\n",
      "Epoch 85 loss is 0.3236\n",
      "Epoch 86 loss is 0.3249\n",
      "Epoch 87 loss is 0.3155\n",
      "Epoch 88 loss is 0.3175\n",
      "Epoch 89 loss is 0.3202\n",
      "Epoch 90 loss is 0.3186\n",
      "Epoch 91 loss is 0.3205\n",
      "Epoch 92 loss is 0.3157\n",
      "Epoch 93 loss is 0.3181\n",
      "Epoch 94 loss is 0.3191\n",
      "Epoch 95 loss is 0.3150\n",
      "Epoch 96 loss is 0.3110\n",
      "Epoch 97 loss is 0.3021\n",
      "Epoch 98 loss is 0.3040\n",
      "Epoch 99 loss is 0.3086\n",
      "Epoch 100 loss is 0.3010\n"
     ]
    }
   ],
   "source": [
    "ts = TrafficSign(num_classes = 43).to('cuda')\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(ts.parameters(), lr=1e-3)\n",
    "\n",
    "for epoch in range(100):\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for images, labels in dataloader_train:\n",
    "        images = images.to('cuda')\n",
    "        labels = labels.to('cuda')\n",
    "        optimizer.zero_grad()\n",
    "        outputs = ts(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    epoch_loss = running_loss/len(dataloader_train)\n",
    "    print(f'Epoch {epoch + 1} loss is {epoch_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14cac7dd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-13T15:02:01.741474Z",
     "iopub.status.busy": "2024-09-13T15:02:01.741037Z",
     "iopub.status.idle": "2024-09-13T15:02:01.774836Z",
     "shell.execute_reply": "2024-09-13T15:02:01.773539Z"
    },
    "papermill": {
     "duration": 0.050824,
     "end_time": "2024-09-13T15:02:01.777337",
     "exception": false,
     "start_time": "2024-09-13T15:02:01.726513",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Width  Height  Roi.X1  Roi.Y1  Roi.X2  Roi.Y2  ClassId            Path\n",
      "0     53      54       6       5      48      49       16  Test/00000.png\n",
      "1     42      45       5       5      36      40        1  Test/00001.png\n",
      "2     48      52       6       6      43      47       38  Test/00002.png\n",
      "3     27      29       5       5      22      24       33  Test/00003.png\n",
      "4     60      57       5       5      55      52       11  Test/00004.png\n"
     ]
    }
   ],
   "source": [
    "print(pd.read_csv('/kaggle/input/gtsrb-german-traffic-sign/Test.csv').head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e5d24b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-13T15:02:01.806536Z",
     "iopub.status.busy": "2024-09-13T15:02:01.806106Z",
     "iopub.status.idle": "2024-09-13T15:02:01.815619Z",
     "shell.execute_reply": "2024-09-13T15:02:01.814584Z"
    },
    "papermill": {
     "duration": 0.026319,
     "end_time": "2024-09-13T15:02:01.817830",
     "exception": false,
     "start_time": "2024-09-13T15:02:01.791511",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, csv_file, img_dir, transform=None):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.data.iloc[idx]['Path']  \n",
    "        img_path = os.path.join(self.img_dir, img_name) # NB drop the test in the img_dir because of how path is inputted\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "        label = self.data.iloc[idx]['ClassId']  \n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "855a0ec6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-13T15:02:01.846203Z",
     "iopub.status.busy": "2024-09-13T15:02:01.845461Z",
     "iopub.status.idle": "2024-09-13T15:02:15.352234Z",
     "shell.execute_reply": "2024-09-13T15:02:15.351130Z"
    },
    "papermill": {
     "duration": 13.523699,
     "end_time": "2024-09-13T15:02:15.354760",
     "exception": false,
     "start_time": "2024-09-13T15:02:01.831061",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 4, 13, 10,  ...,  8, 10,  3])\n"
     ]
    }
   ],
   "source": [
    "test_trans = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((128,128))\n",
    "])\n",
    "\n",
    "dataset_test = TestDataset(\n",
    "    csv_file = '/kaggle/input/gtsrb-german-traffic-sign/Test.csv',\n",
    "    img_dir='/kaggle/input/gtsrb-german-traffic-sign/',\n",
    "    transform= test_trans\n",
    ")\n",
    "\n",
    "dataloader_test = DataLoader(\n",
    "    dataset_test,\n",
    "    shuffle = True,\n",
    "    batch_size = 1500\n",
    ")\n",
    "\n",
    "#change dataloader batch size to 1 before running \n",
    "image, label = next(iter(dataloader_test))\n",
    "# print(image.shape)\n",
    "# image = image.squeeze().permute(1,2,0)\n",
    "# print(image.shape)\n",
    "# plt.imshow(image)\n",
    "# plt.show()\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d18a6025",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-13T15:02:15.381876Z",
     "iopub.status.busy": "2024-09-13T15:02:15.381430Z",
     "iopub.status.idle": "2024-09-13T15:03:55.491802Z",
     "shell.execute_reply": "2024-09-13T15:03:55.490520Z"
    },
    "papermill": {
     "duration": 100.138353,
     "end_time": "2024-09-13T15:03:55.505962",
     "exception": false,
     "start_time": "2024-09-13T15:02:15.367609",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:0.05859065800905228\n",
      "Accuracy:0.05859065800905228\n",
      "Recall:0.05859065800905228\n"
     ]
    }
   ],
   "source": [
    "from torchmetrics import Accuracy, Precision, Recall\n",
    "recall = Recall(task='multiclass', num_classes=43, average='micro').to('cuda')\n",
    "accuracy = Accuracy(task='multiclass', num_classes=43, average='micro').to('cuda')\n",
    "precision = Precision(task='multiclass', num_classes=43, average='micro').to('cuda')\n",
    "\n",
    "ts.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in dataloader_test:\n",
    "        images, labels = images.to('cuda'), labels.to('cuda')\n",
    "        outputs = ts(images)\n",
    "        _, preds = torch.max(outputs,1)\n",
    "        precision(preds, labels)\n",
    "        accuracy(preds, labels)\n",
    "        recall(preds, labels)\n",
    "\n",
    "ts_precision = precision.compute()\n",
    "ts_accuracy = accuracy.compute()\n",
    "ts_recall = recall.compute()\n",
    "\n",
    "print(f'Precision:{ts_precision}\\nAccuracy:{ts_accuracy}\\nRecall:{ts_recall}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1443ce05",
   "metadata": {
    "papermill": {
     "duration": 0.012427,
     "end_time": "2024-09-13T15:03:55.530720",
     "exception": false,
     "start_time": "2024-09-13T15:03:55.518293",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 82373,
     "sourceId": 191501,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30762,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 20775.183211,
   "end_time": "2024-09-13T15:03:57.267160",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-09-13T09:17:42.083949",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
