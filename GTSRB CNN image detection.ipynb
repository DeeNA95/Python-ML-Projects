{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":191501,"sourceType":"datasetVersion","datasetId":82373}],"dockerImageVersionId":30761,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n%ls '/kaggle/input/gtsrb-german-traffic-sign/Train/'","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-09-13T00:27:52.938651Z","iopub.execute_input":"2024-09-13T00:27:52.939158Z","iopub.status.idle":"2024-09-13T00:27:54.618139Z","shell.execute_reply.started":"2024-09-13T00:27:52.939104Z","shell.execute_reply":"2024-09-13T00:27:54.616324Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"\u001b[0m\u001b[01;34m0\u001b[0m/   \u001b[01;34m11\u001b[0m/  \u001b[01;34m14\u001b[0m/  \u001b[01;34m17\u001b[0m/  \u001b[01;34m2\u001b[0m/   \u001b[01;34m22\u001b[0m/  \u001b[01;34m25\u001b[0m/  \u001b[01;34m28\u001b[0m/  \u001b[01;34m30\u001b[0m/  \u001b[01;34m33\u001b[0m/  \u001b[01;34m36\u001b[0m/  \u001b[01;34m39\u001b[0m/  \u001b[01;34m41\u001b[0m/  \u001b[01;34m6\u001b[0m/  \u001b[01;34m9\u001b[0m/\n\u001b[01;34m1\u001b[0m/   \u001b[01;34m12\u001b[0m/  \u001b[01;34m15\u001b[0m/  \u001b[01;34m18\u001b[0m/  \u001b[01;34m20\u001b[0m/  \u001b[01;34m23\u001b[0m/  \u001b[01;34m26\u001b[0m/  \u001b[01;34m29\u001b[0m/  \u001b[01;34m31\u001b[0m/  \u001b[01;34m34\u001b[0m/  \u001b[01;34m37\u001b[0m/  \u001b[01;34m4\u001b[0m/   \u001b[01;34m42\u001b[0m/  \u001b[01;34m7\u001b[0m/\n\u001b[01;34m10\u001b[0m/  \u001b[01;34m13\u001b[0m/  \u001b[01;34m16\u001b[0m/  \u001b[01;34m19\u001b[0m/  \u001b[01;34m21\u001b[0m/  \u001b[01;34m24\u001b[0m/  \u001b[01;34m27\u001b[0m/  \u001b[01;34m3\u001b[0m/   \u001b[01;34m32\u001b[0m/  \u001b[01;34m35\u001b[0m/  \u001b[01;34m38\u001b[0m/  \u001b[01;34m40\u001b[0m/  \u001b[01;34m5\u001b[0m/   \u001b[01;34m8\u001b[0m/\n","output_type":"stream"}]},{"cell_type":"code","source":"print(pd.read_csv('/kaggle/input/gtsrb-german-traffic-sign/Train.csv').head())","metadata":{"execution":{"iopub.status.busy":"2024-09-13T00:27:54.621154Z","iopub.execute_input":"2024-09-13T00:27:54.622020Z","iopub.status.idle":"2024-09-13T00:27:54.745651Z","shell.execute_reply.started":"2024-09-13T00:27:54.621961Z","shell.execute_reply":"2024-09-13T00:27:54.744337Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"   Width  Height  Roi.X1  Roi.Y1  Roi.X2  Roi.Y2  ClassId  \\\n0     27      26       5       5      22      20       20   \n1     28      27       5       6      23      22       20   \n2     29      26       6       5      24      21       20   \n3     28      27       5       6      23      22       20   \n4     28      26       5       5      23      21       20   \n\n                             Path  \n0  Train/20/00020_00000_00000.png  \n1  Train/20/00020_00000_00001.png  \n2  Train/20/00020_00000_00002.png  \n3  Train/20/00020_00000_00003.png  \n4  Train/20/00020_00000_00004.png  \n","output_type":"stream"}]},{"cell_type":"code","source":"from torchvision.datasets import ImageFolder\nfrom torch.utils.data import DataLoader\nfrom torchvision import transforms\nimport matplotlib.pyplot as plt\nimport torch.optim as optim\n\ntrain_trans = transforms.Compose([\n    transforms.RandomRotation(9.6),\n    transforms.RandomAutocontrast(),\n    transforms.ToTensor(),\n    transforms.Resize((128,128))\n])\n\ndata_train = ImageFolder(\n    '/kaggle/input/gtsrb-german-traffic-sign/Train',\n    transform= train_trans\n)\n\ndataloader_train = DataLoader(\n    data_train,\n    shuffle = True,\n    batch_size = 1000\n)\n\n#change dataloader batch size to 1 before running \n# image, label = next(iter(dataloader_train))\n# print(image.shape)\n# image = image.squeeze().permute(1,2,0)\n# print(image.shape)\n# plt.imshow(image)\n# plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-09-13T00:27:54.747221Z","iopub.execute_input":"2024-09-13T00:27:54.747577Z","iopub.status.idle":"2024-09-13T00:28:26.957590Z","shell.execute_reply.started":"2024-09-13T00:27:54.747539Z","shell.execute_reply":"2024-09-13T00:28:26.956119Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"import torch.nn as nn\nclass TrafficSign(nn.Module):\n    def __init__(self, num_classes):\n        super().__init__()\n        self.feature_extractor = nn.Sequential(\n            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n            nn.ELU(),\n            nn.MaxPool2d(kernel_size=2),\n            nn.Conv2d(32, 64, kernel_size=3, padding =1),\n            nn.ELU(),\n            nn.MaxPool2d(kernel_size=2),\n            nn.Flatten()\n        )\n        self.classifier = nn.Linear(64*32*32, num_classes)\n        \n    def forward(self, x):\n        x = self.feature_extractor(x)\n        x= self.classifier(x)\n        return x \n    \n    ","metadata":{"execution":{"iopub.status.busy":"2024-09-13T00:28:26.959264Z","iopub.execute_input":"2024-09-13T00:28:26.959838Z","iopub.status.idle":"2024-09-13T00:28:26.969796Z","shell.execute_reply.started":"2024-09-13T00:28:26.959791Z","shell.execute_reply":"2024-09-13T00:28:26.968424Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"ts = TrafficSign(num_classes = 43).to('cuda')\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(ts.parameters(), lr=1e-3)\n\nfor epoch in range(10):\n    running_loss = 0.0\n    \n    for images, labels in dataloader_train:\n        optimizer.zero_grad()\n        outputs = ts(images)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        running_loss += loss.item()\n    \n    epoch_loss = running_loss/len(dataloader_train)\n    print(f'Epoch {epoch + 1} loss is {epoch_loss:.4f}')","metadata":{"execution":{"iopub.status.busy":"2024-09-13T00:28:26.972969Z","iopub.execute_input":"2024-09-13T00:28:26.973672Z","iopub.status.idle":"2024-09-13T00:28:28.041664Z","shell.execute_reply.started":"2024-09-13T00:28:26.973608Z","shell.execute_reply":"2024-09-13T00:28:28.038946Z"},"trusted":true},"execution_count":5,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)","Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m ts \u001b[38;5;241m=\u001b[39m \u001b[43mTrafficSign\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m43\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n\u001b[1;32m      3\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(ts\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-3\u001b[39m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1174\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1171\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1172\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m-> 1174\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:780\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    778\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    779\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 780\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    782\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    783\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    784\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    785\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    790\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    791\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:780\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    778\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    779\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 780\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    782\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    783\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    784\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    785\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    790\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    791\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:805\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    801\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    802\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    803\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    804\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 805\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    806\u001b[0m p_should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    808\u001b[0m \u001b[38;5;66;03m# subclasses may have multiple child tensors so we need to use swap_tensors\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1160\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1153\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m   1154\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(\n\u001b[1;32m   1155\u001b[0m             device,\n\u001b[1;32m   1156\u001b[0m             dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1157\u001b[0m             non_blocking,\n\u001b[1;32m   1158\u001b[0m             memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format,\n\u001b[1;32m   1159\u001b[0m         )\n\u001b[0;32m-> 1160\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1161\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1162\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1163\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1164\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1165\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot copy out of meta tensor; no data!\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/cuda/__init__.py:305\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    300\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    301\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    302\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultiprocessing, you must use the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspawn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m start method\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    303\u001b[0m     )\n\u001b[1;32m    304\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(torch\u001b[38;5;241m.\u001b[39m_C, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_cuda_getDeviceCount\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 305\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTorch not compiled with CUDA enabled\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    306\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _cudart \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    307\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[1;32m    308\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    309\u001b[0m     )\n","\u001b[0;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"],"ename":"AssertionError","evalue":"Torch not compiled with CUDA enabled","output_type":"error"}]}]}